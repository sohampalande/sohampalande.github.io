---
layout: about
title: about
permalink: /
subtitle: <strong>Research</strong> at <a href='https://www.jpmorgan.com/technology/artificial-intelligence'>J.P. Morgan AI Research</a>

profile:
  align: left
  image: prof_pic.jpg
  image_circular: True # crops the image to make it circular !
  # address: >
  #   <p>555 your office number</p>
  #   <p>123 your address street</p>
  #   <p>Your City, State 12345</p>

news: true  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---


Hi, I'm Soham. I'm currently a research engineer in [J.P. Morgan's AI Research](https://www.jpmorgan.com/technology/artificial-intelligence) group.

<strong>Research:</strong>  I study how **abstract reasoning** and **decision-making** emerge in large neural networks, and how this parallels the structure of human cognition. My work bridges cognitive science, neuroscience, psychology, and machine learning: I study tasks that demand belief formation, planning, and strategic adaptation, and mechanistically dissect how models—and by analogy, brains—solve them. I use tools from interpretability and ideas from probabilistic cognition to reverse-engineer internal circuits for reasoning, beyond perception. Language and vision form the inputs over which reasoning unfolds, but the core interest lies in how internal models are constructed, updated, and used. Studying these processes in artificial systems offers a new lens on the brain and the self—while insights from neuroscience and psychology can refine how we understand and design the models themselves. My work treats reasoning and higher-level cognition as mechanistic phenomena, and seeks to uncover the machinery behind them to bring us closer to understanding what it means to be *human*.



<!-- 
I study how machine and human models of cognition exhibit **strategic reasoning** in structured, multi-step environments—and their emergence through behavioral evaluation, learned representational structures (from language and fine-tuning), and mechanistic insight in stylized decision-making scenarios involving **uncertainty**, **adaptation**, and **long-term planning**—such as bidding, bluffing, or probabilistic inference—where optimal strategies must be inductively discovered rather than precomputed.

My goal is to understand *when* and *how* models demonstrate intelligent, goal-directed behaviors, and precisely which internal structures—learned, emergent, or structurally implicit—support these capabilities. This involves behavioral analysis, algorithmic investigation, and mechanistic insight, drawing from **game theory**, **cognitive modeling**, and **computational geometry**. I'm particularly interested in how adaptive reasoning naturally develops in response to incentives, reinforced feedback signals, inductive contexts, and the geometric structure of internal language representations.

Ultimately, through empirical evaluations, my work addresses deeper theoretical questions—such as how models inductively simulate, generalize, or abstract analogously to human cognition in scientific and mathematical reasoning. By studying reasoning within computational systems and natural cognition through a computational lens, I aim to uncover **generalizable principles of intelligent behavior**, enabling the design of more powerful and adaptive systems. -->



<!-- My interests lie broadly in interpretability for sequential data — both mechanistic and statistical — with applications in finance and healthcare. I'm particularly focused on building <b>scalable</b>, <b>interpretable</b> tools/models for multi-modal models (specifically sequential) that exploit the geometric structure of the underlying data, loss surfaces, and domain-specific mathematical constraints. -->
  

<!-- <ul>
  <li class="">Designing mechanisms to <b>define</b> and <b>detect</b> distribution shifts in various types of data in real time</li>
  <li class="">Building models that are <b>robust</b> to such shifts through:
    <ul>
      <li>Continual Learning</li>
      <li>Few Shot Learning</li>
      <li>Synthetic Data Generation</li>
      <li>Loss function engineering</li>
    </ul>
  </li>
</ul> -->

<strong>Previously:</strong> I graduated from [Rutgers University-NB](https://www.rutgers.edu/) majoring in Computer Science and Mathematics. I was an R&D intern at [L3Harris](https://www.l3harris.com/) where I worked on building anomaly detection models. 

<!-- 
Write your biography here. Tell the world about yourself. Link to your favorite [subreddit](http://reddit.com). You can put a picture in, too. The code is already in, just name your picture `prof_pic.jpg` and put it in the `img/` folder.

Put your address / P.O. box / other info right below your picture. You can also disable any these elements by editing `profile` property of the YAML header of your `_pages/about.md`. Edit `_bibliography/papers.bib` and Jekyll will render your [publications page](/al-folio/publications/) automatically.

Link to your social media connections, too. This theme is set up to use [Font Awesome icons](http://fortawesome.github.io/Font-Awesome/) and [Academicons](https://jpswalsh.github.io/academicons/), like the ones below. Add your Facebook, Twitter, LinkedIn, Google Scholar, or just disable all of them. -->
